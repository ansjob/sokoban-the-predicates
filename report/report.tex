\documentclass[a4paper,11pt]{article}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{numprint}
\usepackage{url}
\usepackage{moreverb}
\usepackage{cite}
\pagestyle{fancy}

\newcommand{\tab}{\hspace*{2em}}
\title{A reverse and backwards Sokoban solver \\ }
\author{Andreas Sj�berg \\ \url{ansjob@kth.se} 
		\and Andreas Gabrielsson \\ \url{andregus@kth.se} 
		\and Marcus Larsson \\ \url{marcular@kth.se}
	}

\fancypagestyle{plain}
{
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
	\fancyfoot[C]{}
}

\begin{document}

\thispagestyle{plain}
\maketitle

\begin{abstract}
The abstract goes here
\end{abstract}

\clearpage

\tableofcontents

\clearpage

\section{Introduction}
This paper is a description of the Sokoban solver we have implemented for the course
DD2380 Artificial Intelligence in the fall of 2012.

\section{Problem statement}

The problem is, given a Sokoban board, to find a sequence of movements that renders the
board into a solved state.
A solved state is a state where all the boxes are placed on a goal.
The movements can be one of the directions \verb!up!, \verb!down!, \verb!left!, or \verb!right!.

The boards are represented using a standard Sokoban format. See this link for details:
\url{http://sokobano.de/wiki/index.php?title=Level_format}.


\section{Method}

We have implemented this as a search in the state space that a certain board defines.
When we find a path between the starting state and a state that is a goal,
we find the transitions between all these states and concatenate them to get a solution.

\subsection{State definition}

So what do we mean by a state of Sokoban?
In our implementation, a state consists of a set of coordinates where the boxes are located,
and the set of coordinates where you can push them from.
This definition has the nice property that the agent can move around in the
open space where it is without transferring to a new state,
but it also captures the fact that states can be different depending on the agent's position.

The coordinate system we have used in our implementation is the same as used in computer graphics.
That is, the top left corner is defined to be the origin, and a coordinate is defined to be
$(row, col)$. 

\subsubsection{Example}
Take a look at the board below for example.
In this board, the box locations would be
$\{(2, 1), (2, 4), (3, 4)\}$,
and the push-from-positions would be
$\{(1,1), (1, 3), (1, 5), (2, 3), (2, 5)\}$.
Note that neighbours to the boxes are not included if the space opposite
the box is not open.

\begin{verbatimtab}
#######
#.@ # #
#$* $ #
#   $ #
# ..  #
#  *  #
#######
\end{verbatimtab}

\subsection{Finding a transition between states}

A transition between two states consists of walking up to a box and pushing it.
An inherent problem with the way our states are defined is that there is no location
where the agent is located included, so the walking up to a box part becomes impossible to solve.
To remedy this, we decided to include the location of the agent in the state,
but \emph{not} consider it in the equality function.

With this information, the problem is very solvable.
The first part is accomplished with a flooding-algorithm that
determines the walking distance to every reachable coordinate in a breadth
first manner until it finds the target, and then follows the trail back to
where the agent stood in the last transition.
The second part (pushing the box) is straight forward, it is only a matter 
of finding the direction of the box to push relative the push-from position.
%Detta borde nog f�rklaras b�ttre. Tittar p� det senare.


\subsection{Finding a winning path}

\subsection{Eliminating dead states}

\section{Results}

\subsection{Performance Optimizations}

\section{Discussion}

\section{Conclusions}


\end{document}

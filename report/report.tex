\documentclass[a4paper,11pt]{article}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{numprint}
\usepackage{url}
\usepackage{moreverb}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{cite}
\pagestyle{fancy}

\newcommand{\tab}{\hspace*{2em}}
\title{A reverse and backwards Sokoban solver \\ }
\author{Andreas Sj√∂berg \\ \url{ansjob@kth.se} 
		\and Andreas Gabrielsson \\ \url{andregus@kth.se} 
		\and Marcus Larsson \\ \url{marcular@kth.se}
	}

\fancypagestyle{plain}
{
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
	\fancyfoot[C]{}
}

\begin{document}

\thispagestyle{plain}
\maketitle

\begin{abstract}
This report describes the implementation of a Sokoban puzzle game solver,
for the course in artificial intelligence.
The Sokoban puzzle is a popular AI research area, as it proves to be quite
the difficult problem to solve.
Our implementation includes bi-directional best-first-searches with various
optimizations for avoiding deadlocks, limiting memory usage and maximizing
efficiency.
The report concludes that while decent results were obtained with our implementation,
many further improvements can be done to solve the more difficult puzzles for this game.
\end{abstract}

\clearpage

\tableofcontents

\clearpage

\section{Introduction}
This paper is a report describing the Sokoban puzzle solver we have implemented for the course
DD2380 Artificial Intelligence in the fall of 2012.

\section{Problem statement}

In the game of Sokoban, the player takes the role of a warehouse keeper in a
(usually maze-like) warehouse with boxes in it.
The warehouse also contains certain positions (goal positions) where the boxes \emph{should} be located.
The objective of the game is to push each of the boxes so that all boxes end up
in a goal position.
To push a box, the player has to stand next to the box,
and the square onto which the box is pushed has to be empty.

In other words, the problem for us to solve is implementing an agent that,
given a Sokoban board, finds the sequence of moves for the player so that
it solves the puzzle.
The movements can be one of the directions \verb!up!, \verb!down!, \verb!left!, or \verb!right!.

The boards are represented using a standard Sokoban format. See this link for details:
\url{http://sokobano.de/wiki/index.php?title=Level_format}.

\section{Method}

The first observation we made was that we could divide the problem into two sub-problems
to simplify our implementation.
First we need to find the (valid) sequence of pushed boxes that are required to solve
the puzzle, and after that we must solve the, much simpler, problem of moving the player
between the various boxes that should be pushed.
Given a sequence of two boxes that should be pushed (basically two positions in a maze),
finding the moves in between these push-actions is trivial.

With this breakdown of the problem, the remaining problem is to find the
sequence of boxes pushed.
To solve this, we have implemented a search in the state space that a given puzzle defines.
When we find a path between the starting state and the solved state (where each box is in a goal position),
we simply find the transitions between all of these states and concatenate these to get a complete solution.

\subsection{State definition}

So what do we mean by a state in Sokoban?
The naive definition of a state could include the whole puzzle,
including the positions of the boxes, the player.
Including walls and goal positions in the state would be wasteful,
as they can never be moved throughout the game.

In our implementation, a state simply consists of the set of coordinates where the boxes are located,
and the set of coordinates next to a box that the player can currently reach.
With this definition, the player is able to move freely in the
open area where it currently is, without entering a different state.
Yet it still captures the difference between two states where the player is on a different side of a
box it is unable to move around.

%XXX "wall" example goes here

Furthermore, by using sets of coordinates rather than matrices with the boxes in,
we save some space, since the number of boxes will always be less than the number of squares in any
given puzzle.
The coordinate system we have used in our implementation is the same as in computer graphics.
That is, the top left corner is defined to be the origin, and a coordinate is defined to be
$(row, col)$.

%XXX - include state example
\subsubsection{Example}
Take a look at the board below for example.
In this board, the box locations would be
$\{(2, 1), (2, 4), (3, 4)\}$,
and the push-from-positions would be
$\{(1,1), (2,2), (2,3), (2,5), (3,1), (3,3), (3,5)\} $.

\begin{verbatimtab}
 0123456
0#######
1#.@ # #
2#$* $ #
3#   $ #
4# ..  #
5#  *  #
6#######
\end{verbatimtab}

\subsection{Finding a transition between states}

A transition between two states consists of walking up to a box and pushing it.
An inherent problem with the way our states are defined is that it does not include the location
of the player, so the moving up to a box part becomes impossible to solve because
we do not know from where to start moving.
To remedy this, we simply include the location of the player in the state,
but do \emph{not} consider it when comparing states.

With this information, the problem is very solvable.
The first part is accomplished with a flooding-algorithm that
determines the walking distance to every reachable coordinate in a breadth
first manner until it finds the target, and then follows the trail back to
where the player stood in the last transition.
The second part (pushing the box) is straight forward, it is only a matter 
of finding the direction of the box to push relative the push-from position.

\subsection{Finding a winning path}

There are two major approaches to solving Sokoban puzzles; forwards and backwards solvers.
The forwards solvers simply starts in the state the board is in and expands a search node
by pushing a box and moving the player.
The backwards algorithm starts in each possible end state of the game,
and expands a search node by \emph{pulling} a box.
The possible end states of the game are simple to find;
they consist of the states where all boxes are on a goal, and the player
is standing next to a box.

In our implementation, we decided to use both methods.
The reason for this is because some puzzles are designed to be difficult
for forward-solvers, and some are designed to be difficult for backwards-solvers.
This way, we get the benefits that each method offer.
Also, the usual benefits of bidirectional search makes this approach compelling.

To implement the bidirectional search, we have the two different algorithms
for forward and backwards searching, and they alternate in execution.
If one of them detects that they are visiting a state the other has already visited,
a solution has been found, and the paths are ''stitched together'' to form the answer.

\subsubsection{Prioritizing states}
\label{sec:prio}

Since the state-space grows rapidly, there is a need to
prioritize the order in which the states are explored.
We decided to use a best-first-search approach for both directions of the search.
Given a good evaluation function, best-first-search is a reasonable
approach, since it will explore states close to the solution first.
This is to prefer compared to for example an $A*$ algorithm,
because we are not concerned with how deep in the
search tree we have explored, we only need to find 
\emph{a} solution as quick as possible.

We implemented three evaluation functions that given a state return an integer value in the range
$[0, 99]$, where higher is better.
One function is a mobility value, one is a value designed to make
it more prioritized to move boxes close to the last box moved,
and the last one is the percentage of boxes on a goal.
We considered having a distance function that would get a ''better score''
when boxes are moving closer to a goal, but this was not very efficient
because it did not take into account the fact that the agent could push several boxes
close to the same goal to get a good score.
This may be due to any of the following reasons;
	we computed the Manhattan distance between a box and a goal,
	we ignored any walls in between the box and the goal,
	and we computed the distance between a box and \emph{the closest} goal, which may not be correct.

\subsection{Eliminating dead states}


We implemented the simplest type of dead state detection we could think of,
namely to avoid pushing boxes into static dead positions in the puzzle.
By static dead positions we mean positions where if the map was empty,
we could not move a box in that position into any of the goals.

The algorithm for this is simple, and runs one time before the search starts.

\clearpage
\begin{algorithm}
\caption{Marking Sokoban board positions as static dead or alive}
\label{alg:dead_positions}
\begin{algorithmic}
	\Function{DeadPositions}{$board$}
		\For {$position \in board$}
			\State $position \gets dead$
		\EndFor
		\For {$goal \in board.goals$}
			\For {$position \in board$}
				\If {\Call{CanPullFromTo}{$goal$, $position$}}
					\State $position \gets alive$
				\EndIf
			\EndFor
		\EndFor
	\EndFunction
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:dead_positions} will mark corners and positions along the
''outer walls'' as statically dead, unless they contain a goal or a path to a goal.
In the example below, the dead positions have been marked with \verb!X!.
There are of course significantly more dead situations but this simple approach 
allows us to prune lots of dead states with little effort.

\begin{verbatimtab}
 0123456
0#######
1#. X#X#
2# .  X#
3#    X#
4# .. X#
5#X . X#
6#######

\end{verbatimtab}

The other dead states are not as static as the ones discussed above. 
It can for example be when four boxes are pushed together in a two times two square when they are not on a goal.
In the backwards solver this particular kind of dead state is not really a problem since it is
impossible to pull four boxes to such a square.
In the forward solver this problem is tackled by using the mobility value discussed in section~\ref{sec:prio}. 

There are even more dead states that are harder to detect but those are not considered. 



\section{Results}

\subsection{Performance Optimizations}

In order to squeeze some better performance out of the implementation we implemented
the coordinates using the multiton pattern.
This means there will not be several object instances for the same coordinate,
but only reference to the same one.
This saves lots of memory, since many states will have references to the same coordinates.

\section{Discussion}

\section{Conclusions}


\end{document}

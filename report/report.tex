\documentclass[a4paper,11pt]{article}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{numprint}
\usepackage{url}
\usepackage{moreverb}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{cite}
\pagestyle{fancy}

\newcommand{\tab}{\hspace*{2em}}
\title{A reverse and backwards Sokoban solver \\ }
\author{Andreas Sj√∂berg \\ \url{ansjob@kth.se} 
		\and Andreas Gabrielsson \\ \url{andregus@kth.se} 
		\and Marcus Larsson \\ \url{marcular@kth.se}
	}

\fancypagestyle{plain}
{
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
	\fancyfoot[C]{}
}

\begin{document}

\thispagestyle{plain}
\maketitle

\begin{abstract}
The abstract goes here
\end{abstract}

\clearpage

\tableofcontents

\clearpage

\section{Introduction}
This paper is a description of the Sokoban solver we have implemented for the course
DD2380 Artificial Intelligence in the fall of 2012.

\section{Problem statement}

The problem is, given a Sokoban board, to find a sequence of movements that renders the
board into a solved state.
A solved state is a state where all the boxes are placed on a goal.
The movements can be one of the directions \verb!up!, \verb!down!, \verb!left!, or \verb!right!.

The boards are represented using a standard Sokoban format. See this link for details:
\url{http://sokobano.de/wiki/index.php?title=Level_format}.


\section{Method}

We have implemented this as a search in the state space that a certain board defines.
When we find a path between the starting state and a state that is a goal,
we find the transitions between all these states and concatenate them to get a solution.

\subsection{State definition}

So what do we mean by a state in Sokoban?
In our implementation, a state consists of a set of coordinates where the boxes are located,
and the set of coordinates next to a box that are reachable.
This definition has the nice property that the agent can move around in the
open space where it is without transferring to a new state,
but it also captures the fact that states can be different depending on the agent's position.

The coordinate system we have used in our implementation is the same as used in computer graphics.
That is, the top left corner is defined to be the origin, and a coordinate is defined to be
$(row, col)$. 

\subsubsection{Example}
Take a look at the board below for example.
In this board, the box locations would be
$\{(2, 1), (2, 4), (3, 4)\}$,
and the push-from-positions would be
$\{(1,1), (2,2), (2,3), (2,5), (3,1), (3,3), (3,5)\} $.

\begin{verbatimtab}
 0123456
0#######
1#.@ # #
2#$* $ #
3#   $ #
4# ..  #
5#  *  #
6#######
\end{verbatimtab}

\subsection{Finding a transition between states}

A transition between two states consists of walking up to a box and pushing it.
An inherent problem with the way our states are defined is that there is no location
where the agent is located included, so the walking up to a box part becomes impossible to solve.
To remedy this, we decided to include the location of the agent in the state,
but \emph{not} consider it in the equality function.

With this information, the problem is very solvable.
The first part is accomplished with a flooding-algorithm that
determines the walking distance to every reachable coordinate in a breadth
first manner until it finds the target, and then follows the trail back to
where the agent stood in the last transition.
The second part (pushing the box) is straight forward, it is only a matter 
of finding the direction of the box to push relative the push-from position.

\subsection{Finding a winning path}

There are two major approaches to solving Sokoban maps; forwards and backwards solvers.
The forwards solvers simply starts in the state the board is in and expands a search node
by pushing a box and moving the agent.
The backwards algorithm starts in each possible end state of the game,
and expands a search node by \emph{pulling} a box.
The possible end states of the game are simple to find;
they consist of the states where all boxes are on a goal, and the agent
is standing next to a box.

In our implementation, we decided to use both methods.
The reason for this is because some maps are designed to be difficult
for forward-solvers, and some are designed to be difficult for backwards-solvers.
This way, we get the benefits that each method offer.
Also, the usual benefits of bidirectional search makes this approach compelling.

To implement the bidirectional search, we have the two different algorithms
for forward and backwards searching, and they alternate in execution.
If one of them detects that they are visiting a state the other has already visited,
a solution has been found, and the paths are ''stitched together'' to form the answer.

\subsubsection{Prioritizing states}
\label{sec:prio}

We decided to use a best-first-search approach for both directions of the search,
and so we had to come up with a way to prioritize states.
We implemented two functions that both return an integer value in the range
$[0, 99]$, where higher is better.
One function is a mobility value, and the other is the percentage of boxes on a goal.
We considered having a distance function that would get a ''better score''
when boxes are moving closer to a goal, but this was not very efficient
because it did not take into account the fact that the agent could push several boxes
close to the same goal to get a good score.
This may be due to any of the following reasons;
	we computed the Manhattan distance between a box and a goal,
	we ignored any walls in between the box and the goal,
	and we computed the distance between a box and \emph{the closest} goal, which may not be correct.

\subsection{Eliminating dead states}


We implemented the simplest type of dead state detection we could think of,
namely to avoid pushing boxes into static dead positions on the map.
By static dead positions we mean positions where if the map was empty,
we could not move a box in that position into any of the goals.

The algorithm for this is simple, and runs one time before the search starts.

\clearpage
\begin{algorithm}
\caption{Marking Sokoban board positions as static dead or alive}
\label{alg:dead_positions}
\begin{algorithmic}
	\Function{DeadPositions}{$board$}
		\For {$position \in board$}
			\State $position \gets dead$
		\EndFor
		\For {$goal \in board.goals$}
			\For {$position \in board$}
				\If {\Call{CanPullFromTo}{$goal$, $position$}}
					\State $position \gets alive$
				\EndIf
			\EndFor
		\EndFor
	\EndFunction
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:dead_positions} will mark corners and positions along the
''outer walls'' as statically dead, unless they contain a goal or a path to a goal.
In the example below, the dead positions have been marked with \verb!X!.
There are of course significantly more dead situations but this simple approach 
allows us to prune lots of dead states with little effort.

\begin{verbatimtab}
 0123456
0#######
1#. X#X#
2# .  X#
3#    X#
4# .. X#
5#X . X#
6#######

\end{verbatimtab}

The other dead states are not as static as the ones discussed above. 
It can for example be when four boxes are pushed together in a two times two square when they are not on a goal.
In the backwards solver this particular kind of dead state is not really a problem since it is
impossible to pull four boxes to such a square.
In the forward solver this problem is tackled by using the mobility value discussed in section~\ref{sec:prio}. 

There are even more dead states that are harder to detect but those are not considered. 



\section{Results}

\subsection{Performance Optimizations}

In order to squeeze some better performance out of the implementation we implemented
the coordinates using the multiton pattern.
This means there will not be several object instances for the same coordinate,
but only reference to the same one.
This saves lots of memory, since many states will have references to the same coordinates.

\section{Discussion}

\section{Conclusions}


\end{document}
